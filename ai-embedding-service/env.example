# ============================================
# FastAPI Embedding Service - Environment Variables
# ============================================
# Copy this file to .env and update with your actual values

# ============================================
# Server / Compose Inputs
# ============================================
ENVIRONMENT=development
API_HOST=0.0.0.0
API_PORT=8001
LOG_LEVEL=INFO
# Compose wiring
EMBEDDING_HOST_PORT=8001
EMBEDDING_ENV_FILE=./ai-embedding-service/.env.dev

# ============================================
# Model Configuration
# ============================================
# Default embedding model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Device: 'cpu' or 'cuda' (for GPU support)
DEVICE=cpu

# ============================================
# Performance Settings
# ============================================
# Batch size for processing
BATCH_SIZE=32

# Maximum text length
MAX_TEXT_LENGTH=512

# Maximum batch size
MAX_BATCH_SIZE=100

# Normalize embeddings (true/false)
NORMALIZE_EMBEDDINGS=false

# Model cache size
MODEL_CACHE_SIZE=1

# ============================================
# Supported Models
# ============================================
# Comma-separated list of supported models
SUPPORTED_MODELS=all-MiniLM-L6-v2

# ============================================
# CORS Configuration
# ============================================
# Comma-separated list of allowed origins
# Use * for development, specific origins for production
CORS_ORIGINS=*

# ============================================
# Uvicorn Workers (Production)
# ============================================
# Number of worker processes (only used in production)
# UVICORN_WORKERS=1
